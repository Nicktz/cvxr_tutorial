---
title: "The Structure of Atoms"
author: "Anqi Fu and Balasubramanian Narasimhan"
date: "6/9/2019"
slug: cvxr_atom-structure
categories: Developer Guide
---

```{r prereqs, message = FALSE, echo = FALSE}
library(CVXR)
```

TODO: Introduction.

## Function Properties
TODO: Introduction.

### Basic Definition
For any $x \in \mathbf{R}^n$ and $y \in \mathbf{R}$, the quadratic-over-linear atom is defined as
$$
  f(x,y) := \frac{\|x\|_2^2}{y} \quad \mbox{with} \quad \mathbf{dom}\;f = \{(x,y) \in \mathbf{R}^n \times \mathbf{R}: y > 0\}.
$$
TODO: S4 object constructor. Code for validate_args, to_numeric, .domain.

First, we provide a method for validating the input arguments. This method is called during initialization to check whether the arguments make sense for the atom. In our example, the second argument to $f$ must be a scalar, so our validation method looks like
```{r, eval=FALSE}
setMethod("validate_args", "QuadOverLin", function(object) {
  if(!is_scalar(object@args[[2]]))
    stop("The second argument to QuadOverLin must be a scalar.")
  callNextMethod()
})
```
The input `object` is a `QuadOverLin` atom. We access its arguments (which are `Expression` objects) via the `args` slot. Given our initialization, `object@args[[1]]` contains the expression for $x$, and `object@args[[2]]` the one for $y$. We call `is_scalar` on the latter to check if $y$ is indeed scalar.

Notice that we did not check if $y > 0$ during validation. This is because we generally do not know the value of an argument during the construction of a quadratic-over-linear expression - $y$ may contain a `Variable` that we are solving for in our problem, and we cannot define the problem if validation fails. 

How then do we ensure $(x,y) \in \mathbf{dom}\;f$? By defining a method that returns a list of `Constraint`s, which delineate our atom's domain.
```{r, eval=FALSE}
setMethod(".domain", "QuadOverLin", function(object) { list(object@args[[2]] >= 0) })
```
TODO: This method is automatically called to enforce the constraint in a problem? Use of weak inequality.

Both validation and domain methods may be dropped if an atom's arguments span the reals. However, the evaluation method is always required. It takes as input a `QuadOverLin` object and a list `values` containing the numeric values of $x$ and $y$, given in the same order as `atom_args`. TODO: It then computes...
```{r, eval=FALSE}
setMethod("to_numeric", "QuadOverLin", function(object, values) { sum(values[[1]]^2) / values[[2]] })
```
TODO: Reminder that values are numeric, in contrast to args.

### Gradient
If an atom is differentiable, we also provide a method for computing its gradient. TODO: This is because... The gradient of the quadratic-over-linear function is
$$
  \nabla_x f(x,y) = \frac{2x}{y}, \quad \nabla_y f(x,y) = -\frac{\|x\|_2^2}{y^2}
$$
for $(x,y) \in \mathbf{dom}\;f$. We encode it in
```{r, eval=FALSE}
setMethod(".grad", "QuadOverLin", function(object, values) {
  X <- values[[1]]
  y <- as.numeric(values[[2]])
  if(y <= 0)
    return(list(NA_real_, NA_real_))
  else {
    # DX = 2X/y, Dy = -||X||^2_2/y^2
    Dy <- -sum(X^2)/y^2
    Dy <- Matrix(Dy, sparse = TRUE)
    DX <- 2.0*X/y
    DX <- Matrix(as.numeric(t(DX)), sparse = TRUE)
    return(list(DX, Dy))
  }
})
```
where `values` is a list with the numeric values of our inputs $x$ and $y$. For each argument, we compute the gradient vector using standard R operations, wrapping the result in a sparse `Matrix` for memory efficiency. Then, we return a list of the gradients ordered in the same way as the input, i.e., $(\nabla_x f(x,y), \nabla_y f(x,y))$. Note that the gradient is `NA` outside $\mathbf{dom}\;f$.

### Dimension, Sign, and Curvature
For DCP analysis to work, we must explicitly define each atom's dimension, sign, and curvature. It is easy to see that $f$ is scalar-valued, nonnegative, and convex over its domain. These properties are encoded in
```{r, eval=FALSE}
setMethod("dim_from_args", "QuadOverLin", function(object) { c() })
setMethod("sign_from_args",  "QuadOverLin", function(object) { c(TRUE, FALSE) })
setMethod("is_atom_convex", "QuadOverLin", function(object) { TRUE })
setMethod("is_atom_concave", "QuadOverLin", function(object) { FALSE })
```
Here, the `sign_from_args` function returns a vector of two logical values - the first indicates if the atom's value is positive, and the second if it is negative. To enable composition under the DCP rules, we must also define whether the atom is weakly increasing or decreasing in each of its arguments. From its gradient, we see that $f$ is weakly decreasing in $y$, weakly increasing in $x$ on $\mathbf{R}_+^n$, and weakly decreasing in $x$ on $\mathbf{R}_-^n$. These properties are spelled out in the following methods.
```{r, eval=FALSE}
setMethod("is_incr", "QuadOverLin", function(object, idx) { (idx == 1) && is_nonneg(object@args[[idx]]) })
setMethod("is_decr", "QuadOverLin", function(object, idx) { ((idx == 1) && is_nonpos(object@args[[idx]])) || (idx == 2) })
```
The input `idx` is the index of the argument of interest. Given our `QuadOverLin` initialization, `idx = 1` corresponds to $x$ and `idx = 2` to $y$. Both of these arguments are stored in the list `object@args` as `Expression` objects, which may encapsulate further constants, variables, and atoms. Consequently, we must call `is_nonneg` (resp. `is_nonpos`) to determine if an argument is nonnegative (resp. nonpositive) according to the DCP composition rules. Note that the inequality `object@args[[1]] >= 0` is **incorrect**, because it returns a `Constraint` rather than the desired logical value. 

### Additional Characteristics
TODO: is_quadratic and is_qpwa.

## Canonicalization
Once `CVXR` verifies a problem is DCP, it then converts that problem into a solver-compatible form. This *canonicalization* process is carried out through a series of calls to individual atom canonicalizers, defined in the reductions framework. To implement an atom, one must explicitly derive its canonicalizer for a particular class of problems (e.g., conic programs), which is supported by the desired solver. We show an approach below that uses its graph implementation.

A function $g: \mathbf{R}^n \rightarrow \mathbf{R}$ is convex if and only if its epigraph
$$
  \mathbf{epi}\;g = \{(x,t) \in \mathbf{R}^n \times \mathbf{R}: g(x) \leq t\}
$$
is a convex set. Then, it can be written as
$$
  g(x) = \inf \{t \in \mathbf{R}: (x,t) \in \mathbf{epi}\;g \}.
$$
A similar relationship exists between concave functions and their hypographs. The *graph implementation* of a function is a representation of its epigraph or hypograph as a disciplined convex feasibility problem. This provides an elegant means of defining a nondifferentiable function in terms of a canonical optimization problem, which can be directly evaluated by a solver.

For instance, the quadratic-over-linear atom can be written as a second-order cone program (SOCP). Given $(x,y) \in \mathbf{dom}\;f$, the inequality $f(x,y) \leq t$ is equivalent to
$$
\begin{align*}
  4\|x\|_2^2 &\leq 4ty = (y+t)^2 - (y-t)^2 \\
  (y-t)^2 + \|2x\|_2^2 &\leq (y+t)^2 \\
  \left\|\begin{pmatrix} y-t \\ 2x \end{pmatrix}\right\|_2 &\leq y+t
\end{align*}
$$
so that
$$
  f(x,y) = \inf \left\{t \in \mathbf{R}: \left(\begin{pmatrix} y-t \\ 2x \end{pmatrix}, y+t\right) \in \mathcal{K} \right\},
$$
where $\mathcal{K} := \{(u,v) \in \mathbf{R}^{n+1} \times \mathbf{R}: \|u\|_2 \leq v\}$ is a second-order cone. Thus, $f(x,y)$ is the solution to an SOCP, which may be evaluated using any conic solver. The canonicalizer for quadratic-over-linear takes as input $(x,y)$ and outputs the above SOCP.

In `CVXR`, this canonicalizer function is defined in dcp2cone.R, since it is used to reduce a DCP problem to a cone program.
```{r, eval=FALSE}
Dcp2Cone.quad_over_lin_canon <- function(expr, args) {
  # quad_over_lin := sum_{ij} X^2_{ij} / y
  x <- args[[1]]
  y <- flatten(args[[2]])
  
  # Pre-condition: dim = c()
  t <- Variable(1)
  
  # (y+t, y-t, 2*x) must lie in the second-order cone, where y+t is the scalar part
  # of the second-order cone constraint
  constraints <- list(SOC(t = y+t, X = VStack(y-t, 2*flatten(x)), axis = 2))
  return(list(t, constraints))
}
```
It takes as input a `QuadOverLin` expression `expr` and a list of arguments `args`, which specify the input values $(x,y)$. The first two lines of the function extract $x$ and $y$ from `args`, and the third line constructs the `Variable` $t \in \mathbf{R}$. The fourth line forms the constraint $\left(\begin{pmatrix} y-t \\ 2x \end{pmatrix}, y+t\right) \in \mathcal{K}$ with a call to the constructor `SOC`. If $x \in \mathbf{R}^n$, then `SOC(t,x)` enforces $\|x\|_2 \leq t$. Finally, the canonicalizer returns a list containing $t$, the epigraph variable, and a list of constraints from the graph implementation - in this case, the single second-order cone constraint.

## Putting It All Together
Suppose we are given $A \in \mathbf{R}^{m \times n}$ and $b \in \mathbf{R}^m$, and would like to solve
$$
  \begin{array}{ll}
    \mbox{minimize} & f(x,y) \\
    \mbox{subject to} & Ax = b
  \end{array}
$$
with respect to $x \in \mathbf{R}^n$ and $y \in \mathbf{R}_{++}$. Substituting in the graph implementation of $f$, our problem can be rewritten as
$$
  \begin{array}{ll}
    \mbox{minimize} & t \\
    \mbox{subject to} & Ax = b,  \quad (x,y) \in \mathbf{dom}\;f, \quad \left(\begin{pmatrix} y-t \\ 2x \end{pmatrix}, y+t\right) \in \mathcal{K},
  \end{array}
$$
where $t \in \mathbf{R}$ is the additional graph variable. If $b \in \mathbf{null}\;A$, the solution is trivially $x^* = \vec{0}$ and any $y^* > 0$. Otherwise, the point $y = 0$ is infeasible, so we can relax the domain constraint to get
$$
    \begin{array}{ll}
    \mbox{minimize} & t \\
    \mbox{subject to} & Ax = b, \quad y \geq 0, \quad \left(\begin{pmatrix} y-t \\ 2x \end{pmatrix}, y+t\right) \in \mathcal{K}.
  \end{array}
$$
This SOCP canonicalization may then be passed into a cone solver to obtain the optimal $t^* = f(x^*,y^*)$. TODO: A few words on how CVXR does this automatically with the canonicalization of the atom.

